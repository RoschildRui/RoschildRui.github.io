---
layout:       post
title:        "[LLM Prompt Recovery](PV:0.6694)é“¶ç‰Œæ–¹æ¡ˆæ€»ç»“(1)"
author:       "Roschild.Rui"
header-style: text
catalog:      true

---
> â€œè¿™æ˜¯æˆ‘çš„ç¬¬ä¸€ä¸ªblogï¼Œå¸Œæœ›åœ¨è¿™ä¸€è·¯ä¸Šèƒ½è®¤è¯†æ›´å¤šå¿—åŒé“åˆçš„æœ‹å‹â€

> "This is my first blog post. Setting out on this path, I am looking forward to meeting more friends who also have greate passion on data science. Together, we will dive into the fascinating world of data, uncover valuable and deeper insights on this Earth, and strive to make a meaningful impact to make people life great 'again' !!!"

### å†™åœ¨å‰é¢
åœ¨è¿™ä¸€ç¯‡blogä¸­æˆ‘ä¼šå…ˆç®€å•ä»‹ç»æˆ‘ä»¬å›¢é˜Ÿçš„æœ€ç»ˆæäº¤æ–¹æ¡ˆ**(`PV=0.6694`,`PB=0.6659`)**

éšåæ•´ä¸ªæ–¹æ¡ˆçš„è¿­ä»£å½¢æˆè¿‡ç¨‹å°†åœ¨æˆ‘æ¥ä¸‹æ¥çš„blogä¸­é€ä¸€å‘ˆç°

åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿä¼šåœ¨æ¥ä¸‹æ¥çš„blogä¸­é€šè¿‡å¤ç°é‡‘ç‰ŒåŒºä»¥åŠéƒ¨åˆ†ä¼˜ç§€é“¶ç‰ŒåŒºçš„æ¯”èµ›æ–¹æ¡ˆï¼Œåæ€æ€»ç»“ï¼Œä»¥æœŸåŠ æ·±æˆ‘ä»¬å¯¹äºå¤§æ¨¡å‹çš„ç†è§£

æ„Ÿè°¢ [Kaggle](https://www.kaggle.com/) â€”â€”ä¸€ä¸ªå¼€æ”¾ï¼Œå¯Œæœ‰æ´»åŠ›çš„æ•°æ®ç§‘å­¦ç¤¾åŒºç«èµ›å¹³å°ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†ä¸€æ¬¡æ·±å…¥ç†è§£LLMå†…éƒ¨æœºåˆ¶çš„æœºä¼šã€‚ğŸ˜‰

### [æ¯”èµ›å†…å®¹](https://www.kaggle.com/competitions/llm-prompt-recovery)
**Overview**

LLMs are commonly used to rewrite or make stylistic changes to text. The goal of this competition is to recover the LLM prompt that was used to transform a given text.

**Description**

NLP workflows increasingly involve rewriting text, but there's still a lot to learn about how to **prompt LLMs effectively**. This machine learning competition is designed to be a novel way to dig deeper into this problem.

The challenge: recover the LLM prompt used to rewrite a given text. Youâ€™ll be tested against a dataset of 1300+ original texts, each paired with a rewritten version from Gemma, Googleâ€™s new family of open models.

**Evaluation**

Evaluation Metric

For each row in the submission and corresponding ground truth, sentence-t5-base is used to calculate corresponding embedding vectors. The score for each predicted / expected pair is calculated using the Sharpened Cosine Similarity, using an exponent of 3. The SCS is used to attenuate the generous score given by embedding vectors for incorrect answers. Do not leave any rewrite_prompt blank as null answers will throw an error.

Submission File

The submission file should contain a header and have the following format:

```csv
id,rewrite_prompt
000aaa,"Rewrite this essay but do it using the writing style of Dr. Seuss"
111bbb,"Rewrite this essay but do it using the writing style of William Shakespeare"
222ccc,"Rewrite this essay but do it using the writing style of Tupac Shakur"
...
```


### æ–¹æ¡ˆæ€»ç»“
- 1.æ„å»ºåŸºäºdeberta-v3-largeçš„seq2seqæ¨¡å‹
- 2.æ„å»ºåˆé€‚çš„adapterå±‚å¾®è°ƒ[phi2](https://www.kaggle.com/models/Microsoft/phi/Transformers/2/1)æ¨¡å‹
- 3.few-shot [mistral-7b-v2](https://www.kaggle.com/datasets/ahmadsaladin/mistral-7b-it-v02)æ¨¡å‹

å°†ä¸‰ä¸ªæ¨¡å‹è¿˜åŸçš„æç¤ºè¯é›†æˆåœ¨ä¸€èµ·ä½œä¸ºæœ€ç»ˆçš„é¢„æµ‹ç»“æœ

### è¯„ä»·æŒ‡æ ‡çš„ç†è§£

æˆ‘å°†é€šè¿‡ä¸€ä¸ªå…·ä½“çš„æ•°å­¦ä¾‹å­æ¥å±•ç¤ºé”åŒ–ä½™å¼¦ç›¸ä¼¼åº¦ä¸ä¼ ç»Ÿä½™å¼¦ç›¸ä¼¼åº¦ä¹‹é—´çš„åŒºåˆ«ã€‚è¿›è€Œæ›´å¥½åœ°ç†è§£æ¯”èµ›è¯„ä»·æŒ‡æ ‡çš„å€¾å‘æ€§ã€‚

**ç¤ºä¾‹å‘é‡**

å‡è®¾æˆ‘ä»¬æœ‰ä¸¤å¯¹å‘é‡ï¼Œä¸€å¯¹è¾ƒä¸ºç›¸ä¼¼ï¼Œå¦ä¸€å¯¹è¾ƒä¸ºä¸ç›¸ä¼¼ï¼š

- å‘é‡å¯¹Aï¼ˆè¾ƒä¸ºç›¸ä¼¼ï¼‰:

```math
  $\vec{u}$ = [1, 2, 3.0]
  $\vec{v}$ = [1, 2, 2.9]
```

- å‘é‡å¯¹Bï¼ˆè¾ƒä¸ºä¸ç›¸ä¼¼ï¼‰:

```math
  $\vec{x}$ = [1, 2, 3]
  $\vec{y}$ = [3, 2, 1] 
```

**è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦**

ä½™å¼¦ç›¸ä¼¼åº¦å…¬å¼ä¸ºï¼š

$\text{cosine similarity}$ = $\frac{\vec{a} \cdot \vec{b}}{\|\vec{a}\| \|\vec{b}\|}$

å…¶ä¸­ $\vec{a} \cdot \vec{b} $æ˜¯å‘é‡çš„ç‚¹ç§¯ï¼Œ$\|\vec{a}\|$ å’Œ $\|\vec{b}\|$ æ˜¯å‘é‡çš„æ¨¡ã€‚
 
å¯¹äºå‘é‡å¯¹Aå’ŒBï¼Œè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼š

- å¯¹A:

```math
  $ \vec{u} \cdot \vec{v} = 1*1 + 2*2 + 3*2.9 = 1 + 4 + 8.7 = 13.7 $
  $ \|\vec{u}\| = \sqrt{1^2 + 2^2 + 3^2} = \sqrt{14} $
  $ \|\vec{v}\| = \sqrt{1^2 + 2^2 + 2.9^2} \approx \sqrt{13.61} $
  $ \text{cosine similarity}_{A} = \frac{13.7}{\sqrt{14} \times \sqrt{13.61}} \approx 0.994 $
```

- å¯¹B:

```math
  $ \vec{x} \cdot \vec{y} = 1*3 + 2*2 + 3*1 = 3 + 4 + 3 = 10 $
  $ \|\vec{x}\| = \sqrt{14}, \|\vec{y}\| = \sqrt{14} $
  $ \text{cosine similarity}_{B} = \frac{10}{14} \approx 0.535 $
```

**åº”ç”¨é”åŒ–å¤„ç†ï¼ˆ`p = 3`ï¼‰**

é”åŒ–ä½™å¼¦ç›¸ä¼¼åº¦ä¸º $`\text{cosine similarity}^p`$ï¼Œè¿™é‡Œå– `p = 3`ï¼š

- å¯¹A:

```math
  $ \text{sharpened cosine similarity}_{A} = 0.994^3 \approx 0.982 $
```

- å¯¹B:

```math
  $ \text{sharpened cosine similarity}_{B} = 0.535^3 \approx 0.153 $
```

**åˆ†æç»“æœ**

åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼Œå‘é‡å¯¹Açš„ä½™å¼¦ç›¸ä¼¼åº¦å¾ˆé«˜ï¼ˆæ¥è¿‘1ï¼‰ï¼Œé€šè¿‡é”åŒ–å¤„ç†ï¼Œå®ƒçš„ç›¸ä¼¼åº¦å€¼è™½æœªè¢«è¿›ä¸€æ­¥å¢å¼ºï¼Œä½†å‡å°‘ç›¸å¯¹æœ‰é™ã€‚å¯¹äºå‘é‡å¯¹Bï¼Œé”åŒ–å¤„ç†æ˜¾è‘—é™ä½äº†å®ƒçš„ç›¸ä¼¼åº¦å€¼ï¼Œå‘é‡å¯¹Aä¸å‘é‡å¯¹Bçš„å·®å€¼æ˜¾è‘—æé«˜äº†ã€‚

é€šè¿‡é”åŒ–ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæˆ‘ä»¬å¯ä»¥æ˜æ˜¾åœ°åŒºåˆ†é«˜åº¦ç›¸ä¼¼ã€ä¸€èˆ¬ç›¸ä¼¼ã€å’Œè¿¥å¼‚çš„æƒ…å†µï¼Œé”åŒ–ä½™å¼¦ç›¸ä¼¼åº¦é€šè¿‡**å¼ºåŒ–å·²æœ‰çš„ç›¸ä¼¼åº¦æˆ–å·®å¼‚**ï¼Œ**ä½¿å¾—æ¨¡å‹é¢„æµ‹å€¼æ›´åŠ â€œå°–é”â€**ã€‚

è¿™è¯´æ˜è¿™åœºæ¯”èµ›ä¼šä»¥è¾ƒé«˜çš„ç²¾åº¦åŒºåˆ†éå¸¸ç›¸è¿‘ã€ä¸€èˆ¬ç›¸è¿‘ã€æˆ–è€…è¿¥å¼‚çš„å®ä½“æ–‡æœ¬ã€‚è¿›è€Œå¯¹äºæˆ‘ä»¬çš„åµŒå…¥å‘é‡é¢„æµ‹çš„å‡†ç¡®æ€§æå‡ºäº†å¾ˆé«˜çš„è¦æ±‚ã€‚**ï¼ˆä¹Ÿä¸ºæˆ‘ä»¬åé¢é›†æˆå¤šä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹è¾“å‡ºåŸ‹ä¸‹äº†ä¼ç¬”ï¼‰** ğŸ˜

### æ•°æ®é›†çš„æ„å»º

å› ä¸ºæ¯”èµ›æ–¹æä¾›çš„æ•°æ®**æœ‰é™ç”šè‡³ç­‰åŒäºæ²¡æœ‰**ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½åªæœ‰**ä¸€æ¡**ğŸ˜°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦é¢å¤–æŸ¥æ‰¾ç”Ÿæˆä¸€äº›æ•°æ®ä»¥æ–¹ä¾¿è®­ç»ƒ**ç«¯åˆ°ç«¯æ¨¡å‹**ä»¥åŠ**æ„å»ºæœ¬åœ°cvåº“**

#### æ•°æ®æ¥æº
ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„æ•°æ®æ¥æºï¼Œè¿™é‡Œå¿…é¡»è¦æ„Ÿè°¢kaggle**å¼€æºæ•°æ®é›†çš„å¤§ä½¬ä»¬**ï¼Œä»¥åŠ**æ•´ç†å¼€æºæ•°æ®çš„å¼€æºå¤§ä½¬ä»¬**ï¼ï¼ï¼ğŸ¥³ğŸ¥³ğŸ¥³

**reference**
- [https://www.kaggle.com/code/tomooinubushi/all-in-one-dataset-with-embedding/notebook](https://huggingface.co/datasets/Skylion007/openwebtext)
- [https://huggingface.co/datasets/Skylion007/openwebtext](https://huggingface.co/datasets/Skylion007/openwebtext)
- [https://huggingface.co/datasets/euclaise/writingprompts/viewer/default/train?p=1](https://huggingface.co/datasets/euclaise/writingprompts/viewer/default/train?p=1)
- [https://www.kaggle.com/datasets/nbroad/gemma-rewrite-nbroad](https://www.kaggle.com/datasets/nbroad/gemma-rewrite-nbroad)
- [https://www.kaggle.com/datasets/ilanmeissonnier/chatgpt-rewrite-promts/data](https://www.kaggle.com/datasets/ilanmeissonnier/chatgpt-rewrite-promts/data)
- [https://www.kaggle.com/datasets/winddude/70k-prompt-rewrite-triples/data](https://www.kaggle.com/datasets/winddude/70k-prompt-rewrite-triples/data)
- [https://www.kaggle.com/code/aatiffraz/generating-data-through-gemma7b-1000-texts-5h](https://www.kaggle.com/code/aatiffraz/generating-data-through-gemma7b-1000-texts-5h)
- ...

#### æ•°æ®é¢„å¤„ç†
æˆ‘ä»¬å‘ç°æ•°æ®é›†ä¸­å­˜åœ¨ä¸€äº›æ— æ•ˆä¿¡æ¯ï¼Œä»¥åŠä¸€äº›æœ‰æ•ˆä¿¡æ¯å­˜åœ¨å™ªå£°ï¼Œäºæ˜¯æˆ‘ä»¬ä¸»è¦å‚è€ƒä¸€ä½kaggleçš„experté¢„å¤„ç†æ–¹æ¡ˆå¯¹æ•°æ®é›†è¿›è¡Œäº†**æ­£åˆ™å»å™ª**ï¼ˆæŠ±æ­‰ï¼Œæ‰¾ä¸åˆ°é‚£ä¸ªæ–¹æ¡ˆçš„è¯´æ˜å»å“ªé‡Œäº†ï¼Œæ‰€ä»¥å°±è®©Claudeå†™ä¸€ä¸‹å§ğŸ˜‹ï¼‰

å»å™ªå†…å®¹å¦‚ä¸‹ï¼š
1. å»é™¤æ— ç”¨æˆ–ä¸ç›¸å…³çš„æ–‡æœ¬:
   - åœ¨ç”Ÿæˆçš„`rewritten_text`ä¸­,åŒ…å«ä¸€äº›æ— ç”¨æˆ–ä¸ç›¸å…³çš„æ–‡æœ¬,å¦‚"therefore.*I cannot"ã€"does not contain any"ç­‰ã€‚
   - è¿™äº›æ–‡æœ¬æ˜¯ç”±è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„,ä½†å¹¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„é‡å†™åçš„æ–‡æœ¬ã€‚
   - é€šè¿‡ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¿™äº›æ¨¡å¼,å¹¶å°†åŒ¹é…åˆ°çš„æ–‡æœ¬æ¸…ç©º,å¯ä»¥å»é™¤è¿™äº›æ— ç”¨æˆ–ä¸ç›¸å…³çš„æ–‡æœ¬ã€‚

2. æå–ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µ:
   - åœ¨æŸäº›æƒ…å†µä¸‹,`rewritten_text`ä¸­åŒ…å«ä¸€äº›å›ºå®šçš„æ¨¡å¼,å¦‚"Sure, here.*?:"ã€"Summary of .*?\n\n"ç­‰ã€‚
   - è¿™äº›æ¨¡å¼åé¢é€šå¸¸è·Ÿç€æˆ‘ä»¬çœŸæ­£æ„Ÿå…´è¶£çš„é‡å†™åçš„æ–‡æœ¬ã€‚
   - é€šè¿‡ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¿™äº›å­æ¨¡å¼,å¹¶ä»åŒ¹é…ä½ç½®çš„æœ«å°¾å¼€å§‹æå–æ–‡æœ¬,å¯ä»¥è·å–åˆ°ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µã€‚

3. å»é™¤å¤šä½™çš„å‰ç¼€æˆ–åç¼€:
   - æœ‰æ—¶ç”Ÿæˆçš„`rewritten_text`åŒ…å«ä¸€äº›å¤šä½™çš„å‰ç¼€æˆ–åç¼€,å¦‚ä»¥"**\n\n"æˆ–"user"å¼€å¤´çš„æ–‡æœ¬ã€‚
   - è¿™äº›å‰ç¼€æˆ–åç¼€æ˜¯ç”±ä¸åŒè¯­è¨€æ¨¡å‹çš„ä¸€äº›ç‰¹æ€§ç”Ÿæˆçš„,ä½†å¯¹äºé‡å†™åçš„æ–‡æœ¬æ¥è¯´æ˜¯å¤šä½™çš„ã€‚
   - é€šè¿‡å»æ‰è¿™äº›å¤šä½™çš„å‰ç¼€æˆ–åç¼€,è·å¾—æ›´å¹²å‡€å’Œå‡†ç¡®çš„é‡å†™åçš„æ–‡æœ¬ã€‚

4. å¤„ç†ç‰¹æ®Šæƒ…å†µ:
   - `fix_prompt`å‡½æ•°ä¸­çš„æ­£åˆ™è¡¨è¾¾å¼å¯ä»¥å¤„ç†ä¸€äº›ç‰¹æ®Šæƒ…å†µã€‚
   - ä¾‹å¦‚,åŒ¹é…"therefore.*I cannot"æ¨¡å¼çš„æ–‡æœ¬è¡¨ç¤ºè¿™ä¸ªå¤§è¯­è¨€æ¨¡å‹å¤§æ¦‚ç‡æ— æ³•ç”Ÿæˆåˆé€‚çš„é‡å†™,å› æ­¤å°†å…¶æ¸…ç©ºã€‚
   - åŒ¹é…"Sure, here.*?:"æ¨¡å¼çš„æ–‡æœ¬å¯èƒ½è¡¨ç¤ºè¯­è¨€æ¨¡å‹ç”Ÿæˆäº†ä¸€äº›å›ºå®šçš„å›å¤æ ¼å¼,éœ€è¦æå–å…¶åçš„ç›¸å…³æ–‡æœ¬ã€‚

**å‚è€ƒä»£ç å¦‚ä¸‹ï¼š**
```python
import re

def fix_prompt(text):
    patterns = [
        r'therefore.*I cannot',
        "does not contain any",
        'am unable to provide',
        "am unable to rewrite",
        "do not have the capacity to write",
        "am unable to engage",
        "I am unable to",
        "not provide information",
    ]
    sub_patterns= [
        r"Sure, here.*?:",
        r"Sure. here.*?:",
        r"Certainly, here.*?:",
        r"here.*? text*?:",
        r"Summary of .*?\n\n",
        r"Analysis of .*?\n\n",
        #r"The text.*?:"
    ]
    for p in patterns:
        match = re.search(p, text, re.IGNORECASE)
        
        if match:
            text = ''
    
    if text=="":
        return text
    else:
        for p in sub_patterns:
            match = re.search(p, text, re.IGNORECASE)
            if match:
                text = text[match.end():]
        if text.startswith('**\n\n') or text.startswith('user'):
            text=text[4:].strip()
        return text
```

#### embeddingæ•°æ®
å°†ä¸Šè¿°æ­¥éª¤å¤„ç†å¥½çš„æ•°æ®ï¼Œé€šè¿‡**sentence-t5-base**æ¨¡å‹ï¼Œç”Ÿæˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„embedding

**å‚è€ƒä»£ç å¦‚ä¸‹ï¼š**
````python
import pandas as pd
import gc
import numpy as np
import pandas as pd
import time
from tqdm import tqdm
import numpy as np
from sentence_transformers import SentenceTransformer
import pickle

df = pd.read_parquet(f"./train_clean.parquet", columns=['rewrite_prompt'])
test= pd.read_csv('./test.csv', usecols=['rewrite_prompt'])

model =  SentenceTransformer('sentence-transformers/sentence-t5-base')
model.max_seq_length = 512

encoded_data = model.encode(list(df['rewrite_prompt']), batch_size=32, device='cuda', show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)
encoded_data = encoded_data.detach().cpu().numpy()
encoded_data = np.asarray(encoded_data.astype('float32'))

np.save('train_emb_sentence-t5.npy', encoded_data)

test_emb = model.encode(list(test['rewrite_prompt']), batch_size=32, device='cuda', show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)
test_emb = test_emb.detach().cpu().numpy()
test_emb = np.asarray(test_emb.astype('float32'))

np.save('test_emb_sentence-t5.npy', test_emb)
```

### è®­ç»ƒdebertaæ¨¡å‹
**[Reference](https://www.kaggle.com/code/alejopaullier/llm-pr-seq2seq-train/notebook)**
æˆ‘ä»¬ä¸»è¦åŸºäºè¿™ä¸ªç¬”è®°æœ¬è¿›è¡Œäº†ä¸€äº›ä¿®æ”¹

#### æ¨¡å‹å‚æ•°è®¾ç½®
```python
class config:
    AMP = True
    BATCH_SIZE_TRAIN = 4
    BATCH_SIZE_VALID = 4
    BETAS = (0.85, 0.999)
    DEBUG = 0 
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    LR = 5e-6
    EPOCHS = 10
    EPS = 1e-8
    GRADIENT_CHECKPOINTING = False
    MODEL = "/kaggle/input/deberta-v3-large-hf-weights"
    CKPT = 'deberta-v3-large'
    MAX_GRAD_NORM = 250000.0
    MAX_LEN = 384
    NUM_WORKERS = 0
    PRINT_FREQ = 500
    SEED = 42
    WANDB = False
    WEIGHT_DECAY = 0.005
```

#### æ¨¡å‹ç»“æ„
æ¨¡å‹ç»“æ„ä¸­æœ‰ä¸¤ä¸ªtricks
- 1.ç›´æ¥ä½¿ç”¨debertaçš„é¢„è®­ç»ƒæƒé‡æå–åŸå§‹æ–‡æœ¬å’Œé‡å†™æ–‡æœ¬çš„ç‰¹å¾ï¼Œæˆ‘ä»¬å‘ç°å…¨å‚æ•°è®­ç»ƒå’Œä½¿ç”¨é¢„è®­ç»ƒæƒé‡åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°**æ²¡æœ‰æ˜¾è‘—çš„å·®åˆ«**ï¼Œåœ¨äº¤å‰éªŒè¯çš„æ—¶å€™ç”šè‡³å‘ç°åœ¨æŸäº›æ—¶å€™ä¼š**å¼±äº**é¢„è®­ç»ƒæƒé‡ï¼Œäºæ˜¯æˆ‘ä»¬å†³å®šç›´æ¥ä½¿ç”¨**é¢„è®­ç»ƒçš„æƒé‡**å¹¶è®¾è®¡äº†ä¸€ä¸ª**å¤´ç»“æ„**ï¼Œè®©è¿™ä¸ªå¤´èƒ½ä»åº•å±‚æ¨¡å‹debertaä¸­æå–çš„ä¸°å¯Œç‰¹å¾ä¸­å­¦ä¹ åˆ°æœ‰ç”¨çš„è¡¨ç¤ºï¼Œè¿›è€Œé€šè¿‡å˜æ¢å’Œå‹ç¼©ï¼Œç”Ÿæˆèƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹é‡å†™æç¤ºçš„åµŒå…¥å‘é‡ã€‚å…³äºä¸ºä»€ä¹ˆå°†ä¸­é—´å±‚ç»´åº¦è®¾ä¸º32256ï¼Œç®€å•æ¥è¯´å°±æ˜¯ç„å­¦ğŸ˜…ï¼Œç¡¬è¦è¯´å°±æ˜¯768*42ï¼Œä¸€èˆ¬å°†**ä¸­é—´å±‚å‘é‡ç»´åº¦è®¾ä¸ºåµŒå…¥å‘é‡ç»´åº¦çš„nå€**ä¼šå–å¾—ä¸é”™çš„æ•ˆæœğŸ˜Šï¼Œè¿™é‡Œæˆ‘ä»¬ç›´æ¥ä»  `n=36`å¼€å§‹å°è¯•æœ€ç»ˆå‘ç°`n=42`å–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚ï¼ˆæˆ‘çš„è¯„ä»·æ˜¯ç»éªŒï¼Œå› ä¸ºæˆ‘ä»¬æ—¢å¸Œæœ›æ¨¡å‹èƒ½ä»debertaæå–åˆ°çš„ç‰¹å¾ä¸­å­¦åˆ°**æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯**åˆå¸Œæœ›ä¸è¦**overfitting**ï¼Œå¦‚æœè§‰å¾—å¤ªç„å­¦ï¼Œç›´æ¥ä½¿ç”¨åé¢ä¸¤ä¸ªæ¨¡å‹é›†æˆæ•ˆæœä¹Ÿè¶³å¤Ÿå–å¾—ä¸é”™çš„æ•ˆæœ**(`PV=0.6573`,`PB=0.6569`åœ¨LBä¸­ç§æ¦œæ’81åï¼ŒåŒæ ·æ˜¯é“¶ç‰Œä½)**ï¼Œè¿™ä¸ªseq2seqæ¨¡å‹å°±å½“çœ‹ä¸€ä¸ªä¹å­äº†ğŸ˜‡ï¼‰
- 2.åœ¨è®¾è®¡çš„å¤´ç»“æ„ä¸­ä½¿ç”¨BatchNormä»£æ›¿LayNormï¼ˆåœ¨å¤šæ¬¡äº¤å‰éªŒè¯ä¸­å¹³å‡æ¶¨ç‚¹**0.003**ï¼‰ï¼Œè¿™æˆ‘è§‰å¾—åªèƒ½ç®—æ˜¯ï¼Œ**å››ä¸ªç‰¹å®š**ï¼Œç‰¹å®šä»»åŠ¡ã€ç‰¹å®šåµŒå…¥æ¨¡å‹ã€ç‰¹å®šè¯„ä»·æŒ‡æ ‡ã€ç‰¹å®šæ•°æ®é›†çš„trick ï¼ˆæˆ‘å°†batch_sizeè®¾ä¸º2ä¾æ—§å¦‚æ­¤ï¼‰ ğŸ¤”
```python
class CustomModel(nn.Module):
    def __init__(self, cfg, config_path=None, mode: str ="train", pretrained=False): 
        super().__init__()
        self.cfg = cfg
        self.mode = mode
        self.dropout = 0.2
        if config_path is None:
            self.config = AutoConfig.from_pretrained(cfg.MODEL, output_hidden_states=True) # output_hidden_states=True è¡¨ç¤ºåœ¨é…ç½®ä¸­å¯ç”¨è¾“å‡ºéšè—çŠ¶æ€çš„é€‰é¡¹,å³åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ä¿å­˜æ¯ä¸€å±‚çš„éšè—çŠ¶æ€ã€‚
            self.config.hidden_dropout = 0.
            self.config.hidden_dropout_prob = 0. # Dropoutç‡
            self.config.attention_dropout = 0. # æ³¨æ„åŠ›æƒé‡çš„dropoutç‡
            self.config.attention_probs_dropout_prob = 0.

        else:
            self.config = torch.load(config_path)

        if pretrained:
            self.model = AutoModel.from_pretrained(cfg.MODEL, config=self.config) #self.configï¼šè¿™æ˜¯ä¸€ä¸ªé…ç½®å¯¹è±¡ï¼ŒåŒ…å«äº†æ¨¡å‹åº”æœ‰çš„é…ç½®ã€‚ç”¨æ¥ä¿®æ”¹é»˜è®¤çš„æ¨¡å‹é…ç½®ï¼Œå¦‚è°ƒæ•´dropoutç‡æˆ–å…¶ä»–æ¶æ„ç›¸å…³çš„è®¾ç½®ã€‚
        else:
            self.model = AutoModel(self.config)

        """
        åŠŸèƒ½ï¼šç”¨äºå¯ç”¨æ¨¡å‹çš„æ¢¯åº¦æ£€æŸ¥ç‚¹åŠŸèƒ½ï¼Œä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†éå¸¸å¤§çš„æ¨¡å‹æ—¶ã€‚
        æ¡ä»¶ï¼šåªæœ‰å½“é…ç½®ï¼ˆself.cfgï¼‰ä¸­çš„ GRADIENT_CHECKPOINTING å±æ€§ä¸º True æ—¶ï¼Œæ‰å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€‚è¿™é€šå¸¸åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šï¼Œæˆ–åœ¨å®ä¾‹åŒ–æ¨¡å‹ç±»ä¹‹å‰è®¾ç½®ã€‚
        æ–¹æ³•ï¼šgradient_checkpointing_enable() æ˜¯ transformers åº“æä¾›çš„æ–¹æ³•ï¼Œå®ƒå…è®¸æ¨¡å‹åœ¨è®­ç»ƒæ—¶ä»…ä¿å­˜å¿…è¦çš„æ¿€æ´»ï¼Œè€Œåœ¨éœ€è¦æ—¶é‡æ–°è®¡ç®—å…¶ä»–æ¿€æ´»ï¼Œä»è€Œå‡å°‘å†…å­˜æ¶ˆè€—ã€‚
        """
        if self.cfg.GRADIENT_CHECKPOINTING:
            self.model.gradient_checkpointing_enable()

        self.head = nn.Sequential(
            nn.Linear(self.config.hidden_size*4, 32256),
            nn.BatchNorm1d(32256),
            nn.ReLU(),
            nn.Linear(32256, 768),
        )
        """
        self._init_weights æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰æ–¹æ³•ï¼Œç”¨äºåˆå§‹åŒ–ä¼ å…¥æ¨¡å—çš„æƒé‡ã€‚æ­¤æ–¹æ³•é€šå¸¸åŒ…å«é’ˆå¯¹ä¸åŒç±»å‹çš„å±‚ï¼ˆå¦‚çº¿æ€§å±‚ã€åµŒå…¥å±‚ã€å±‚å½’ä¸€åŒ–ç­‰ï¼‰çš„ç‰¹å®šåˆå§‹åŒ–ç­–ç•¥ã€‚
        è¿™ç§åˆå§‹åŒ–åŒ…æ‹¬è®¾ç½®æƒé‡çš„åˆå§‹åˆ†å¸ƒï¼ˆå¦‚æ­£æ€åˆ†å¸ƒï¼‰ï¼Œå¹¶å¯¹åç½®è¿›è¡Œé›¶åˆå§‹åŒ–ç­‰ã€‚
        """
        self._init_weights(self.head)

    # å®šä¹‰ _init_weights çš„æ–¹æ³•ï¼Œç”¨äºè‡ªå®šä¹‰æƒé‡åˆå§‹åŒ–ã€‚
    """
    è¿™ä¸ª _init_weights æ–¹æ³•æä¾›äº†ä¸€ä¸ªæƒé‡åˆå§‹åŒ–ç­–ç•¥ï¼Œ
    é’ˆå¯¹ä¸åŒç±»å‹çš„å±‚é‡‡ç”¨äº†æœ€é€‚åˆçš„åˆå§‹åŒ–æ–¹å¼ã€‚æœ‰åŠ©äºæ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚
    """
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            """
            çº¿æ€§å±‚ï¼ˆnn.Linearï¼‰ï¼šå¦‚æœ module æ˜¯ä¸€ä¸ªçº¿æ€§å±‚ï¼Œä¸‹é¢çš„æ–¹æ³•å°†ä½¿ç”¨æ­£æ€åˆ†å¸ƒæ¥åˆå§‹åŒ–å…¶æƒé‡ï¼Œå…¶ä¸­å‡å€¼ (mean) ä¸º 0ï¼Œ
            æ ‡å‡†å·® (std) ä¸º self.config.initializer_rangeã€‚è¿™ä¸ª initializer_range é€šå¸¸æ˜¯åœ¨æ¨¡å‹çš„é…ç½®ä¸­æŒ‡å®šçš„ï¼Œç”¨äºæ§åˆ¶åˆå§‹åŒ–çš„åˆ†å¸ƒèŒƒå›´ã€‚
            å¦‚æœè¯¥å±‚åŒ…å«åç½® (bias)ï¼Œåˆ™å°†åç½®åˆå§‹åŒ–ä¸ºé›¶ã€‚
            """
            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)
            if module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.Embedding):
            """
            åµŒå…¥å±‚ï¼ˆnn.Embeddingï¼‰ï¼šå¦‚æœ module æ˜¯ä¸€ä¸ªåµŒå…¥å±‚ï¼ŒåŒæ ·ä½¿ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–å…¶æƒé‡ã€‚
            å¦‚æœåµŒå…¥å±‚æœ‰ padding_idxï¼ˆä¸€èˆ¬ç”¨äºæ ‡è®°åµŒå…¥çŸ©é˜µä¸­çš„å¡«å……ä½ç½®ï¼‰ï¼Œåˆ™å°†è¿™ä¸ªä½ç½®çš„æƒé‡æ˜¾å¼è®¾ç½®ä¸ºé›¶ã€‚è¿™æ˜¯ä¸ºäº†ç¡®ä¿å¡«å……ä½ç½®çš„åµŒå…¥ä¸ä¼šå¯¹æ¨¡å‹äº§ç”Ÿä»»ä½•å½±å“
            """
            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)
            if module.padding_idx is not None:
                module.weight.data[module.padding_idx].zero_()
        elif isinstance(module, nn.LayerNorm):
            """
            å±‚å½’ä¸€åŒ–ï¼ˆnn.LayerNormï¼‰ï¼šå¦‚æœ module æ˜¯å±‚å½’ä¸€åŒ–å±‚ï¼Œæ–¹æ³•å°†å…¶åç½® (bias) åˆå§‹åŒ–ä¸ºé›¶ï¼Œæƒé‡ (weight) åˆå§‹åŒ–ä¸º 1ã€‚
            å±‚å½’ä¸€åŒ–çš„æƒé‡å’Œåç½®é€šå¸¸ç”¨äºè°ƒæ•´å½’ä¸€åŒ–åæ•°æ®çš„æ¯”ä¾‹å’Œåç§»ã€‚
            """
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def feature(self, inputs):
        """
        self.model(**inputs): è°ƒç”¨é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼Œä¼ å…¥çš„ inputs å­—å…¸åŒ…å«äº†è¯¸å¦‚ input_ids, attention_mask ç­‰é”®å€¼å¯¹ã€‚
        **inputs æ˜¯ Python çš„è¯­æ³•ï¼Œè¡¨ç¤ºå°†å­—å…¸æ‹†åŒ…ä¸ºå…³é”®å­—å‚æ•°ã€‚
        outputs: æ¨¡å‹çš„è¾“å‡ºé€šå¸¸æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªç»„ä»¶çš„å¯¹è±¡ã€‚å¯¹äºè®¸å¤šåŸºäº Hugging Face çš„ Transformer æ¨¡å‹ï¼Œoutputs åŒ…å«äº† last_hidden_stateï¼ˆæœ€åä¸€å±‚çš„éšè—çŠ¶æ€ï¼‰ï¼Œ
        hidden_statesï¼ˆå¦‚æœé…ç½®äº†è¿”å›æ‰€æœ‰éšè—å±‚çš„çŠ¶æ€ï¼‰ï¼Œä»¥åŠå¯èƒ½çš„ attentionsï¼ˆå¦‚æœé…ç½®äº†è¿”å›æ³¨æ„åŠ›æƒé‡ï¼‰ã€‚
        """
        outputs = self.model(**inputs)
        #last_hidden_states = outputs[1]
        feature1 = self.pool(outputs.hidden_states[-1], inputs['attention_mask'])
        feature2 = self.pool(outputs.hidden_states[-2], inputs['attention_mask'])
        """
        torch.cat([feature1, feature2], dim=1): å°† feature1 å’Œ feature2 æ²¿ç€ç¬¬äºŒç»´åº¦ï¼ˆå³ç‰¹å¾ç»´åº¦ï¼‰æ‹¼æ¥èµ·æ¥ã€‚
        è¿™ç§æ–¹å¼èåˆæ¥è‡ªæœ€åä¸¤ä¸ªéšè—å±‚çš„ä¿¡æ¯ï¼Œä½¿å¾—ç”Ÿæˆçš„ç‰¹å¾å‘é‡ä¸ä»…åŒ…å«äº†æœ€ç»ˆå±‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¹Ÿèå…¥äº†ä¹‹å‰å±‚çš„è¯­ä¹‰ç‰¹å¾ã€‚
        è¿”å›çš„ç»“æœæ˜¯ä¸€ä¸ªæ‰©å±•çš„ç‰¹å¾å‘é‡ï¼Œç°åœ¨çš„ç‰¹å¾å¤§å°æ˜¯åŸæ¥æ¯å±‚ç‰¹å¾å¤§å°çš„ä¸¤å€ï¼Œå› ä¸ºå®ƒåŒ…å«äº†ä¸¤å±‚çš„è¾“å‡ºã€‚
        """
        return torch.cat([feature1, feature2], dim=1)

    def forward(self, original_texts, rewritten_texts, rewrite_prompts_embedding):

        original_texts_feature = self.feature(original_texts) # shape (batch_size, 768)
        rewritten_texts_feature = self.feature(rewritten_texts) # shape (batch_size, 768)
        feature = torch.cat([original_texts_feature, rewritten_texts_feature], dim=1) # shape (batch_size, 768 * 2)
        output = self.head(feature)

        if self.mode == "train":
            prompt_embedding = torch.tensor(rewrite_prompts_embedding, device=self.cfg.DEVICE) # shape (batch_size, 768)
        else:
            prompt_embedding = None

        return output, prompt_embedding
```





















